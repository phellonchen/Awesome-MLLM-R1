# Awesome-MLLM-R1
Reasoning in MLLMs: Papers and Resources; Latest Advances on Reasoning of Multimodal Large Language Models (Multimodal R1) ) üçì

<font size=5><center><b> Table of Contents </b> </center></font>
- [Awesome Technique](#awesome-technique)
- [Awesome Datasets](#awesome-datasets)
---

## Awesome Technique
|  Title  |   Code  |   About   |
|:--------|:--------:|:--------:|
|![Star](https://img.shields.io/github/stars/EvolvingLMMs-Lab/open-r1-multimodal.svg?style=social&label=Star) <br> **EvolvingLMMs-Lab/open-r1-multimodal** <br> | [Github](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal) | A fork to add multimodal model training to open-r1 |
|![Star](https://img.shields.io/github/stars/Deep-Agent/R1-V.svg?style=social&label=Star) <br> **Deep-Agent/R1-V** <br> | [Github](https://github.com/Deep-Agent/R1-V) | Witness the aha moment of VLM with less than $3. |
|![Star](https://img.shields.io/github/stars/TideDra/lmm-r1.svg?style=social&label=Star) <br> **TideDra/lmm-r1** <br> | [Github](https://github.com/TideDra/lmm-r1) | Extend OpenRLHF to support LMM RL training for reproduction of DeepSeek-R1 on multimodal tasks. |
|![Star](https://img.shields.io/github/stars/FanqingM/R1-Multimodal-Journey.svg?style=social&label=Star) <br> **FanqingM/R1-Multimodal-Journey** <br> | [Github](https://github.com/FanqingM/R1-Multimodal-Journey) | A jounery to real multimodel R1 ! We are doing on large-scale experiment |
|![Star](https://img.shields.io/github/stars/yuyq96/R1-Vision.svg?style=social&label=Star) <br> **yuyq96/R1-Vision** <br> | [Github](https://github.com/yuyq96/R1-Vision) | R1-Vision: Let's first take a look at the image |

## Awesome Datasets
| Name | Paper | Link | Modalities |
|:-----|:-----:|:----:|:----------:|
| **multimodal-open-r1-8k-verified** | - | [Link](https://huggingface.co/datasets/lmms-lab/multimodal-open-r1-8k-verified) | Vision + Text |
| **R1-Vision** | - | [Link](https://huggingface.co/collections/yuyq96/r1-vision-67a6fb7898423dca453efa83) | Vision + Text |
| **CLEVR-70k-Counting** | - | [Link](https://huggingface.co/datasets/leonardPKU/clevr_cogen_a_train) | Vision + Text |
| **CLEVR-70k-Complex** | - | [Link](https://huggingface.co/datasets/MMInstruction/Clevr_CoGenT_TrainA_70K_Complex) | Vision + Text |
| **GEOQA-8k** | - | [Link](https://huggingface.co/datasets/MMInstruction/Clevr_CoGenT_TrainA_70K_Complex) | Vision + Text |
| **Open-Thoughts-114k** | - | [Link](https://huggingface.co/datasets/leonardPKU/GEOQA_R1V_Train_8K) | Text |
| **OpenThoughts-Unverified-173k** | - | [Link](https://huggingface.co/datasets/open-thoughts/OpenThoughts-Unverified-173k) | Text |

## Citation
If you find this project useful in your research, please consider cite:
```
@misc{chen25mllmr1,
  author       = {Feilong Chen},
  title        = {Awesome-MLLM-R1},
  howpublished = {\url{https://github.com/phellonchen/Awesome-MLLM-R1}},
  note         = {Accessed: 2025-02-15},
  year         = {2025}
}
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=atfortes/phellonchen/Awesome-MLLM-R1&type=Timeline)](https://star-history.com/#atfortes/phellonchen/Awesome-MLLM-R1)
