# Awesome-MLLM-R1
Reasoning in MLLMs: Papers and Resources; Latest Advances on Reasoning of Multimodal Large Language Models (Multimodal R1) ) üçì

<p align="center">
    <b> Curated collection of papers and resources on how to realize multimodal R1.</b>
</p>

<font size=5><center><b> Table of Contents </b> </center></font>
- [Awesome Technique](#awesome-technique)
- [Awesome Datasets](#awesome-datasets)
---

# Awesome Technique
|  Title  |   Code  |   About   |
|:--------|:--------:|:--------:|
|![Star](https://img.shields.io/github/stars/EvolvingLMMs-Lab/open-r1-multimodal.svg?style=social&label=Star) <br> **EvolvingLMMs-Lab/open-r1-multimodal** <br> | [Github](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal) | A fork to add multimodal model training to open-r1 |
|![Star](https://img.shields.io/github/stars/TideDra/lmm-r1.svg?style=social&label=Star) <br> **TideDra/lmm-r1** <br> | [Github](https://github.com/TideDra/lmm-r1) | Extend OpenRLHF to support LMM RL training for reproduction of DeepSeek-R1 on multimodal tasks. |
|![Star](https://img.shields.io/github/stars/FanqingM/R1-Multimodal-Journey.svg?style=social&label=Star) <br> **FanqingM/R1-Multimodal-Journey** <br> | [Github](https://github.com/FanqingM/R1-Multimodal-Journey) | A jounery to real multimodel R1 ! We are doing on large-scale experiment |


